Using your knowledge of Python programming, please implement the given rule as a Python function. 

The function should be defined as follows:

```python
def expected_rule_code(state, action, knowledge_graph):
    # Your code here
    return feedback, success, suggestion
where
feedback: a string, give the action feedback based on success or not.
success: a bool, whether the action is executed successfully, give 'True' or 'False'. If the action type is not the action type in the rule, count as success (e.g., success = True).
suggestion: a string, if the 'action' fails, 'suggestion' would be given based on 'rule', 'state' and 'action'.

Here are examples of the state and action format:

state:
{
    "position": "grass",
    "in_front": "water",
    "visible_objects": [
        {
            "type": "water",
            "x": -1,
            "y": 0
        },
        {
            "type": "grass",
            "x": 1,
            "y": 0
        },
        {
            "type": "grass",
            "x": 0,
            "y": -1
        }, ...
    ],
    "objects_in_view": [
        "sand",
        "stone",
        "water",
        "cow",
        "grass"
    ],
    "near_objects": [
        "water",
        "grass"
    ],
    "status": {
        "health": 9,
        "food": 9,
        "drink": 9,
        "energy": 9
    },
    "inventory": {
        "wood": 1
    }
},

action:
{
    "action_name": "mine",
    "args": {
        "block_name": "tree",
        "amount": 1
    }
},
{
    "action_name": "explore",
    "args": {
        "direction": "west",
        "steps": 5
    }
},
{
    "action_name": "make",
    "args": {
        "tool_name": "wood_pickaxe"
    }
},
{
    "action_name": "place",
    "args": {
        "block_name": "sapling"
    }
}


If the rule involves the need to use your knowledge to make a judgement about an item or action then write the function, LLM_request("question"). 
LLM_request would send the "question" to gpt4, and return the gpt4's response. you just need to write the "question" in the LLM_request. 
LLM_request("question"+"response format") has already been predefined, you can just use it dirtectly. Do not need to define it again in your response. But you need to define the "question" and "response format" carefully.

example: i want to know if the item can be destroyed
the LLM function: LLM_request(f"if the {item} can be heated?" + "only reply True or False")

Additionally, please refer to the information provided in the Knowledge Graph to enrich the content of the suggestions, offering more specific and targeted advice. For example, if a particular object needs to be collected from a certain resource, or crafting a specific tool requires certain raw materials, include these details in the suggestions. 
Knowledge Graph:
<Knowledge Graph>


You should only respond in the format as described below, and do not give example usage or anything else:
RESPONSE FORMAT:
def expected_rule_code(state, action, knowledge_graph):
    # Your code here


